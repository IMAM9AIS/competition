{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#machine learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve,accuracy_score,mean_squared_log_error\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score,mean_squared_error\n",
    "import xgboost as xgb\n",
    "from numpy.linalg import inv\n",
    "from xgboost.sklearn import XGBClassifier,XGBRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import matplotlib.dates\n",
    "import operator\n",
    "from quilt.data.ResidentMario import missingno_data \n",
    "import missingno as msno\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"transformed_train1.csv\")\n",
    "test  = pd.read_csv(\"transformed_test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itrain,itest = train_test_split(range(train.shape[0]),train_size=0.8,random_state = 2017)\n",
    "mask = np.ones(train.shape[0],dtype='int')\n",
    "mask[itrain] = 1\n",
    "mask[itest] = 0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bandgap_energy_ev</th>\n",
       "      <th>formation_energy_ev_natom</th>\n",
       "      <th>id</th>\n",
       "      <th>lattice_angle_alpha_degree</th>\n",
       "      <th>lattice_angle_beta_degree</th>\n",
       "      <th>lattice_angle_gamma_degree</th>\n",
       "      <th>lattice_vector_1_ang</th>\n",
       "      <th>lattice_vector_2_ang</th>\n",
       "      <th>lattice_vector_3_ang</th>\n",
       "      <th>number_of_total_atoms</th>\n",
       "      <th>...</th>\n",
       "      <th>clusters_of_lattices_9</th>\n",
       "      <th>area</th>\n",
       "      <th>area_bucket</th>\n",
       "      <th>atomic_density</th>\n",
       "      <th>nota_10.0</th>\n",
       "      <th>nota_20.0</th>\n",
       "      <th>nota_30.0</th>\n",
       "      <th>nota_40.0</th>\n",
       "      <th>nota_60.0</th>\n",
       "      <th>nota_80.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.4387</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>1</td>\n",
       "      <td>90.0026</td>\n",
       "      <td>90.0023</td>\n",
       "      <td>90.0017</td>\n",
       "      <td>9.9523</td>\n",
       "      <td>8.5513</td>\n",
       "      <td>9.1775</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>73.732755</td>\n",
       "      <td>2</td>\n",
       "      <td>0.102426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.9210</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>2</td>\n",
       "      <td>90.0186</td>\n",
       "      <td>89.9980</td>\n",
       "      <td>120.0025</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>6.1838</td>\n",
       "      <td>23.6287</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>127.626563</td>\n",
       "      <td>5</td>\n",
       "      <td>0.088537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.7438</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>3</td>\n",
       "      <td>90.9688</td>\n",
       "      <td>91.1228</td>\n",
       "      <td>30.5185</td>\n",
       "      <td>9.7510</td>\n",
       "      <td>5.6595</td>\n",
       "      <td>13.9630</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42.049778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.3492</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>4</td>\n",
       "      <td>89.9888</td>\n",
       "      <td>90.0119</td>\n",
       "      <td>120.0017</td>\n",
       "      <td>5.0036</td>\n",
       "      <td>5.0034</td>\n",
       "      <td>13.5318</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>59.629688</td>\n",
       "      <td>2</td>\n",
       "      <td>0.088556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3793</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>5</td>\n",
       "      <td>89.9960</td>\n",
       "      <td>90.0006</td>\n",
       "      <td>119.9893</td>\n",
       "      <td>6.6614</td>\n",
       "      <td>6.6612</td>\n",
       "      <td>24.5813</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>143.093313</td>\n",
       "      <td>5</td>\n",
       "      <td>0.073344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bandgap_energy_ev  formation_energy_ev_natom  id  \\\n",
       "0             3.4387                     0.0680   1   \n",
       "1             2.9210                     0.2490   2   \n",
       "2             2.7438                     0.1821   3   \n",
       "3             3.3492                     0.2172   4   \n",
       "4             1.3793                     0.0505   5   \n",
       "\n",
       "   lattice_angle_alpha_degree  lattice_angle_beta_degree  \\\n",
       "0                     90.0026                    90.0023   \n",
       "1                     90.0186                    89.9980   \n",
       "2                     90.9688                    91.1228   \n",
       "3                     89.9888                    90.0119   \n",
       "4                     89.9960                    90.0006   \n",
       "\n",
       "   lattice_angle_gamma_degree  lattice_vector_1_ang  lattice_vector_2_ang  \\\n",
       "0                     90.0017                9.9523                8.5513   \n",
       "1                    120.0025                6.1840                6.1838   \n",
       "2                     30.5185                9.7510                5.6595   \n",
       "3                    120.0017                5.0036                5.0034   \n",
       "4                    119.9893                6.6614                6.6612   \n",
       "\n",
       "   lattice_vector_3_ang  number_of_total_atoms    ...      \\\n",
       "0                9.1775                   80.0    ...       \n",
       "1               23.6287                   80.0    ...       \n",
       "2               13.9630                   40.0    ...       \n",
       "3               13.5318                   30.0    ...       \n",
       "4               24.5813                   80.0    ...       \n",
       "\n",
       "   clusters_of_lattices_9        area  area_bucket  atomic_density  nota_10.0  \\\n",
       "0                       1   73.732755            2        0.102426          0   \n",
       "1                       0  127.626563            5        0.088537          0   \n",
       "2                       0   42.049778            1        0.051910          0   \n",
       "3                       0   59.629688            2        0.088556          0   \n",
       "4                       0  143.093313            5        0.073344          0   \n",
       "\n",
       "   nota_20.0  nota_30.0  nota_40.0  nota_60.0  nota_80.0  \n",
       "0          0          0          0          0          1  \n",
       "1          0          0          0          0          1  \n",
       "2          0          0          1          0          0  \n",
       "3          0          1          0          0          0  \n",
       "4          0          0          0          0          1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['lattice_angle_alpha_degree', 'lattice_angle_beta_degree',\n",
    "       'lattice_angle_gamma_degree', 'lattice_vector_1_ang',\n",
    "       'lattice_vector_2_ang', 'lattice_vector_3_ang', 'number_of_total_atoms','spacegroup','one_to_two', 'one_to_three', 'two_to_three',\n",
    "       'bucket_sg_ratio_1', 'bucket_sg_ratio_2', 'clusters_of_lattices',\n",
    "       'clusters_of_lattices_0', 'clusters_of_lattices_1',\n",
    "       'clusters_of_lattices_2', 'clusters_of_lattices_3',\n",
    "       'clusters_of_lattices_4', 'clusters_of_lattices_5',\n",
    "       'clusters_of_lattices_6', 'clusters_of_lattices_7',\n",
    "       'clusters_of_lattices_8', 'clusters_of_lattices_9','area_bucket', 'atomic_density', 'nota_10.0', 'nota_20.0', 'nota_30.0',\n",
    "       'nota_40.0', 'nota_60.0', 'nota_80.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target1 = 'bandgap_energy_ev'\n",
    "target2 = 'formation_energy_ev_natom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[target1] = np.log1p(train[target1])\n",
    "train[target2] = np.log1p(train[target2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying to use tensor flow regression implementation for guessing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.1\n",
    "training_epochs = 5000\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data_frame(df):\n",
    "    df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[mask]\n",
    "validate_X = train[~mask]\n",
    "\n",
    "\n",
    "train_Y1 = train_X[target1].as_matrix()\n",
    "train_Y2 = train_X[target2].as_matrix()\n",
    "train_X = train_X[features].as_matrix()\n",
    "\n",
    "\n",
    "validate_Y1 = validate_X[target1].as_matrix()\n",
    "validate_Y2 = validate_X[target2].as_matrix()\n",
    "validate_X = validate_X[features].as_matrix()\n",
    "\n",
    "test_X =  test[features].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = normalize_data_frame(train_X)\n",
    "validate_X = normalize_data_frame(validate_X)\n",
    "test_X = normalize_data_frame(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = train_X.shape[0]\n",
    "n_features = train_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples,n_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.T\n",
    "validate_X = validate_X.T\n",
    "test_X = test_X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y1 = train_Y1.reshape(1,-1)\n",
    "train_Y2 =  train_Y2.reshape(1,-1)\n",
    "validate_Y1 = validate_Y1.reshape(1,-1)\n",
    "validate_Y2 = validate_Y2.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1918)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_net_model(X_data,num_features):\n",
    "   \n",
    "    \n",
    "    W1 = tf.Variable(tf.random_normal([1024,num_features]))\n",
    "    B1 = tf.Variable(tf.zeros([1024,1]))\n",
    "    layer_1 = tf.add(tf.matmul(W1,X_data), B1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    print(layer_1.shape)\n",
    "    \n",
    "  \n",
    "    \n",
    "        \n",
    "    W2 = tf.Variable(tf.random_normal([512,1024]))\n",
    "    B2 = tf.Variable(tf.zeros([512,1]))\n",
    "    layer_2 = tf.add(tf.matmul(W2,layer_1), B2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    W3 = tf.Variable(tf.random_normal([64,512]))\n",
    "    B3 = tf.Variable(tf.zeros([64,1]))\n",
    "    layer_3 = tf.add(tf.matmul(W3,layer_2), B3)\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    print(layer_3.shape)\n",
    "\n",
    "    W4 = tf.Variable(tf.random_normal([2,64]))\n",
    "    B4 = tf.Variable(tf.zeros([2,1]))\n",
    "    layer_4 = tf.add(tf.matmul(W4,layer_3), B4)\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    WO = tf.Variable(tf.random_normal([1,2]))\n",
    "    BO = tf.Variable(tf.zeros([1,1]))\n",
    "    output = tf.add(tf.matmul(WO,layer_4), BO)\n",
    "    \n",
    "    print(output.shape)\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, ?)\n",
      "(64, ?)\n",
      "(1, ?)\n"
     ]
    }
   ],
   "source": [
    "xs = tf.placeholder(\"float\")\n",
    "ys = tf.placeholder(\"float\")\n",
    "output = deep_net_model(xs,32)\n",
    "cost =  tf.reduce_mean(tf.square(tf.transpose(output)-tf.transpose(ys)))\n",
    "train_optimizer = tf.train.AdamOptimizer(0.05).minimize(cost)\n",
    "c_train = []\n",
    "c_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31879073,  0.31871232,  0.45087223, -0.05021896, -0.05021896,\n",
       "        0.02705461,  0.2746621 ,  0.77686474, -0.030057  ,  0.03061246,\n",
       "        0.03062073, -0.07776081, -0.07335552, -0.06895024, -0.07776081,\n",
       "       -0.07776081, -0.07335552, -0.07776081, -0.07776081, -0.07776081,\n",
       "       -0.07776081, -0.07776081, -0.07776081, -0.07776081, -0.05573438,\n",
       "       -0.07738187, -0.07776081, -0.07776081, -0.07776081, -0.07776081,\n",
       "       -0.07776081, -0.07335552])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  : 200  cost:  [0.20932114]\n",
      "0.457516267083\n",
      "0.457557250492\n",
      "epoch  : 400  cost:  [0.17943984]\n",
      "0.423603406185\n",
      "0.423660581004\n",
      "epoch  : 600  cost:  [0.14562197]\n",
      "0.381604508819\n",
      "0.381685793041\n",
      "epoch  : 800  cost:  [0.11248385]\n",
      "0.335386144271\n",
      "0.335501076053\n",
      "epoch  : 1000  cost:  [0.082991622]\n",
      "0.288082656007\n",
      "0.288243464588\n",
      "epoch  : 1200  cost:  [0.058753677]\n",
      "0.242391537972\n",
      "0.24261414157\n",
      "epoch  : 1400  cost:  [0.040244944]\n",
      "0.200611452244\n",
      "0.20091608132\n",
      "epoch  : 1600  cost:  [0.027094616]\n",
      "0.164604423694\n",
      "0.165014739797\n",
      "epoch  : 1800  cost:  [0.018413659]\n",
      "0.135696936141\n",
      "0.136235433306\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    for i in range(1,2000):\n",
    "        sess.run([cost,train_optimizer],feed_dict = {xs:train_X,ys:train_Y2})\n",
    "        \n",
    "        c_train.append(sess.run([cost],feed_dict = {xs:train_X,ys:train_Y2}))\n",
    "        c_validation.append(sess.run([cost],feed_dict = {xs:validate_X,ys:validate_Y2}))\n",
    "        if(i % display_step == 0):\n",
    "            print(\"epoch  :\", i, \" cost: \", c_train[i-1])\n",
    "            pred_validation = sess.run(output,feed_dict = {xs:validate_X})\n",
    "            pred_train      = sess.run(output,feed_dict = {xs:train_X})\n",
    "            print(np.sqrt(mean_squared_error(pred_train,train_Y2)))\n",
    "            print(np.sqrt(mean_squared_error(pred_validation,validate_Y2)))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
